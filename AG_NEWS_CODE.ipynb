{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27844944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f313812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bs4) (4.13.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->bs4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from beautifulsoup4->bs4) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead897b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1957ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 0.3.13 (from versions: none)\n",
      "ERROR: No matching distribution found for 0.3.13\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub 0.3.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b445a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import joblib\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from transformers import RobertaTokenizerFast, TFRobertaModel\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPool1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TextClassificationPipeline,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b672d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "3              30000\n",
      "2              30000\n",
      "4              30000\n",
      "1              30000\n",
      "Class Index        1\n",
      "Name: count, dtype: int64\n",
      "class\n",
      "1    15000\n",
      "2    15000\n",
      "3    15000\n",
      "4    15000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jothi\\AppData\\Local\\Temp\\ipykernel_24784\\1793310825.py:10: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(\"class\", group_keys=False).apply(lambda x: x.sample(frac=0.5, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the full dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\jothi\\Desktop\\AG NEWS PROJECT\\train.csv\", header=None, names=[\"class\", \"title\", \"description\"])\n",
    "\n",
    "# Check class distribution\n",
    "print(df[\"class\"].value_counts())\n",
    "\n",
    "# Sample 50% from each class to maintain balance\n",
    "sampled_df = df.groupby(\"class\", group_keys=False).apply(lambda x: x.sample(frac=0.5, random_state=42))\n",
    "\n",
    "# Confirm new distribution\n",
    "print(sampled_df[\"class\"].value_counts())\n",
    "\n",
    "# Save the subset if needed\n",
    "sampled_df.to_csv(\"train_50_percent.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd643e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "3              1900\n",
      "2              1900\n",
      "4              1900\n",
      "1              1900\n",
      "Class Index       1\n",
      "Name: count, dtype: int64\n",
      "class\n",
      "1    950\n",
      "2    950\n",
      "3    950\n",
      "4    950\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jothi\\AppData\\Local\\Temp\\ipykernel_24784\\2862552802.py:10: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(\"class\", group_keys=False).apply(lambda x: x.sample(frac=0.5, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the full dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\jothi\\Desktop\\AG NEWS PROJECT\\test.csv\", header=None, names=[\"class\", \"title\", \"description\"])\n",
    "\n",
    "# Check class distribution\n",
    "print(df[\"class\"].value_counts())\n",
    "\n",
    "# Sample 50% from each class to maintain balance\n",
    "sampled_df = df.groupby(\"class\", group_keys=False).apply(lambda x: x.sample(frac=0.5, random_state=42))\n",
    "\n",
    "# Confirm new distribution\n",
    "print(sampled_df[\"class\"].value_counts())\n",
    "\n",
    "# Save the subset if needed\n",
    "sampled_df.to_csv(\"test_50_percent.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abf5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "\n",
    "# Load the sampled dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\jothi\\Desktop\\AG NEWS PROJECT\\train_50_percent.csv\")\n",
    "df = pd.read_csv(r\"C:\\Users\\jothi\\Desktop\\AG NEWS PROJECT\\test_50_percent.csv\")\n",
    "\n",
    "# Combine title and description for richer input\n",
    "df[\"text\"] = df[\"title\"].fillna(\"\") + \" \" + df[\"description\"].fillna(\"\")\n",
    "\n",
    "# Basic text cleaning\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)            # Normalize whitespace\n",
    "    return text.strip().lower()\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"class\"])\n",
    "\n",
    "# Optional: Split into train/val for internal validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[\"clean_text\"], df[\"label\"], test_size=0.2, stratify=df[\"label\"], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95efa2ef",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fda0625",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Class Distribution - Train\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m---> 10\u001b[0m sns\u001b[38;5;241m.\u001b[39mcountplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_df\u001b[49m, palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass Distribution - Train Set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass Label\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#•\tVisualize class distribution using bar charts.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --------------------------\n",
    "# Class Distribution - Train\n",
    "# --------------------------\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"label\", data=train_df, palette=\"viridis\")\n",
    "plt.title(\"Class Distribution - Train Set\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks([0,1,2,3], [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"])\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# Class Distribution - Test\n",
    "# --------------------------\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"label\", data=test_df, palette=\"magma\")\n",
    "plt.title(\"Class Distribution - Test Set\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks([0,1,2,3], [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da0e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#•\tGenerate word clouds for each category.\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------\n",
    "# Generate word clouds per category\n",
    "# --------------------------\n",
    "categories = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "for label, category in categories.items():\n",
    "    text_data = \" \".join(train_df[train_df[\"label\"] == label][\"text\"].astype(str).tolist())\n",
    "    \n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color=\"white\",\n",
    "        colormap=\"viridis\",\n",
    "        max_words=100\n",
    "    ).generate(text_data)\n",
    "    \n",
    "    plt.subplot(2, 2, label+1)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud - {category}\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45425cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Word Count Calculation\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m train_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_count\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39msplit()))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Average word count per class\u001b[39;00m\n\u001b[0;32m     12\u001b[0m avg_word_count \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_count\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# \tAverage word count per article\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --------------------------\n",
    "# Word Count Calculation\n",
    "# --------------------------\n",
    "train_df[\"word_count\"] = train_df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Average word count per class\n",
    "avg_word_count = train_df.groupby(\"label\")[\"word_count\"].mean()\n",
    "\n",
    "# Category names\n",
    "categories = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    "\n",
    "# --------------------------\n",
    "# Plot\n",
    "# --------------------------\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.barplot(x=avg_word_count.index, y=avg_word_count.values, palette=\"viridis\")\n",
    "\n",
    "plt.title(\"Average Word Count per Article\", fontsize=14)\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Average Word Count\")\n",
    "plt.xticks([0,1,2,3], [categories[i] for i in avg_word_count.index])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\tDescription/title length distribution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --------------------------\n",
    "# Calculate word counts\n",
    "# --------------------------\n",
    "train_df[\"title_len\"] = train_df[\"title\"].apply(lambda x: len(str(x).split()))\n",
    "train_df[\"desc_len\"]  = train_df[\"description\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# --------------------------\n",
    "# Plot distributions\n",
    "# --------------------------\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Title length distribution\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(train_df[\"title_len\"], bins=30, kde=True, color=\"skyblue\")\n",
    "plt.title(\"Title Length Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Number of Words in Title\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Description length distribution\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(train_df[\"desc_len\"], bins=30, kde=True, color=\"salmon\")\n",
    "plt.title(\"Description Length Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Number of Words in Description\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87149a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# •\tCreate a heatmap showing frequent words per class.\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# --------------------------\n",
    "# Simple tokenizer (remove non-alphabetic, lowercase, split)\n",
    "# --------------------------\n",
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", str(text))  # keep only letters\n",
    "    return text.lower().split()\n",
    "\n",
    "# --------------------------\n",
    "# Get top words per class\n",
    "# --------------------------\n",
    "categories = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    "top_n = 15   # top N words to display\n",
    "\n",
    "word_freqs = {}\n",
    "\n",
    "for label, cat_name in categories.items():\n",
    "    texts = train_df[train_df[\"label\"] == label][\"text\"].astype(str).tolist()\n",
    "    tokens = []\n",
    "    for t in texts:\n",
    "        tokens.extend(tokenize(t))\n",
    "    counter = Counter(tokens)\n",
    "    most_common = dict(counter.most_common(top_n))\n",
    "    word_freqs[cat_name] = most_common\n",
    "\n",
    "# --------------------------\n",
    "# Convert to DataFrame\n",
    "# --------------------------\n",
    "df_heatmap = pd.DataFrame(word_freqs).fillna(0).astype(int).T  # classes as rows\n",
    "\n",
    "# --------------------------\n",
    "# Plot Heatmap\n",
    "# --------------------------\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.heatmap(df_heatmap, cmap=\"YlGnBu\", annot=True, fmt=\"d\")\n",
    "plt.title(f\"Top {top_n} Frequent Words per Class\", fontsize=16)\n",
    "plt.ylabel(\"Category\")\n",
    "plt.xlabel(\"Word\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dabb86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e8e408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize text\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=256)\n",
    "val_encodings = tokenizer(list(X_val), truncation=True, padding=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e23018ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (4.56.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb48c42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 3800/3800 [00:00<00:00, 70142.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, ClassLabel\n",
    "\n",
    "# Convert pandas to HF Dataset\n",
    "dataset = Dataset.from_pandas(df_train[[\"text\", \"label\"]])\n",
    "\n",
    "# Manually cast 'label' column to ClassLabel\n",
    "features = dataset.features.copy()\n",
    "features[\"label\"] = ClassLabel(names=[\"world\", \"sports\", \"business\", \"sci/tech\"])  # Adjust if needed\n",
    "dataset = dataset.cast(features)\n",
    "\n",
    "# Now stratified split will work\n",
    "dataset = dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\", seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34d9fe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 3800/3800 [00:00<00:00, 498026.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Features, ClassLabel, Value\n",
    "\n",
    "# Step 1: Create the dataset\n",
    "dataset = Dataset.from_pandas(df_train[[\"text\", \"label\"]])\n",
    "\n",
    "# Step 2: Define features with ClassLabel\n",
    "features = Features({\n",
    "    \"text\": Value(\"string\"),\n",
    "    \"label\": ClassLabel(num_classes=4)  # Adjust if you have more/less classes\n",
    "})\n",
    "\n",
    "# Step 3: Cast dataset to use ClassLabel\n",
    "dataset = dataset.cast(features)\n",
    "\n",
    "# Step 4: Now perform stratified split\n",
    "dataset = dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\", seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aa53686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (4.56.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ef4c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.54.1)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Using cached transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.56.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --user transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7affa46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3be846b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (4.56.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jothi\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jothi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c211f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_ids, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ced1095",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Lambda(lambda inputs: inputs[0] + inputs[1])([input_ids, attention_mask])\n",
    "model = Model(inputs=[input_ids, attention_mask], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8f2457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 5s/step - accuracy: 0.6658 - loss: 0.9447 - val_accuracy: 0.7789 - val_loss: 0.6844\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m496s\u001b[0m 5s/step - accuracy: 0.8020 - loss: 0.6253 - val_accuracy: 0.8224 - val_loss: 0.5755\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 5s/step - accuracy: 0.8293 - loss: 0.5418 - val_accuracy: 0.8184 - val_loss: 0.5441\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 5s/step - accuracy: 0.8342 - loss: 0.5031 - val_accuracy: 0.8250 - val_loss: 0.5117\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 5s/step - accuracy: 0.8408 - loss: 0.4746 - val_accuracy: 0.8329 - val_loss: 0.4965\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 5s/step - accuracy: 0.8484 - loss: 0.4574 - val_accuracy: 0.8289 - val_loss: 0.4925\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 5s/step - accuracy: 0.8533 - loss: 0.4421 - val_accuracy: 0.8421 - val_loss: 0.4838\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m584s\u001b[0m 6s/step - accuracy: 0.8543 - loss: 0.4271 - val_accuracy: 0.8329 - val_loss: 0.4879\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 5s/step - accuracy: 0.8612 - loss: 0.4181 - val_accuracy: 0.8434 - val_loss: 0.4703\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 6s/step - accuracy: 0.8674 - loss: 0.4067 - val_accuracy: 0.8408 - val_loss: 0.4724\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 5s/step\n",
      "Accuracy: 0.8407894736842105\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precision_recall_fscore_support' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_true, y_pred))\n\u001b[1;32m---> 83\u001b[0m precision, recall, f1, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMacro Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMacro Recall:    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'precision_recall_fscore_support' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_id'] = label_encoder.fit_transform(df['label'])\n",
    "y = to_categorical(df['label_id'])\n",
    "\n",
    "#  Split data\n",
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(\n",
    "    df['clean_text'].tolist(), y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "#  Load tokenizer from fine-tuned model\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "#  Tokenize\n",
    "train_encodings = tokenizer(\n",
    "    X_train_texts,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=128,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    X_test_texts,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=128,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "base_model = TFAutoModel.from_pretrained(\n",
    "    model_name,\n",
    "    from_pt=True\n",
    ")\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "# Inputs\n",
    "input_ids = Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_mask = Input(shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "# Lambda wrapper with explicit output shape\n",
    "def bert_layer(inputs):\n",
    "    input_ids, attention_mask = inputs\n",
    "    bert_output = base_model(input_ids, attention_mask=attention_mask)[0]\n",
    "    return bert_output[:, 0, :]  # [CLS] token\n",
    "\n",
    "cls_token = Lambda(\n",
    "    bert_layer,\n",
    "    output_shape=(base_model.config.hidden_size,)\n",
    ")([input_ids, attention_mask])\n",
    "\n",
    "# Classification head\n",
    "output = Dense(y_train.shape[1], activation='softmax')(cls_token)\n",
    "\n",
    "# Final model\n",
    "model_bert = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "model_bert.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train\n",
    "history = model_bert.fit(\n",
    "    [train_encodings['input_ids'], train_encodings['attention_mask']],\n",
    "    y_train,\n",
    "    validation_data=([test_encodings['input_ids'], test_encodings['attention_mask']], y_test),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "#  Evaluate\n",
    "y_pred_probs = model_bert.predict([test_encodings['input_ids'], test_encodings['attention_mask']])\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "print(f\"Macro Precision: {precision:.4f}\")\n",
    "print(f\"Macro Recall:    {recall:.4f}\")\n",
    "print(f\"Macro F1 Score:  {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f596a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(4, 3))  # Small size\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfa85de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer_bert(epoch=10)_model.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model_bert, \"transformer_bert(epoch=10)_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56dbac3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_bert.save(\"transformer_bert(epoch=10)_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcabc323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              title  \\\n",
      "0      0  Large Explosion Heard in Central Baghdad (Reut...   \n",
      "1      0         Israel OKs More West Bank Settlement Homes   \n",
      "2      0          Scores of Iraqis die in 3 days of attacks   \n",
      "3      0                 At least 20 dead in Kurkik bombing   \n",
      "4      0                     Israel, Egypt in Prisoner Swap   \n",
      "\n",
      "                                         description  \\\n",
      "0  Reuters - A large blast was heard in central\\B...   \n",
      "1  JERUSALEM Aug. 23, 2004 - Israel announced pla...   \n",
      "2  US troops fought a gunbattle with insurgents a...   \n",
      "3  A suicide attacker detonated a car bomb near a...   \n",
      "4   CAIRO (Reuters) - Israel released six Egyptia...   \n",
      "\n",
      "                                                text  \n",
      "0  Large Explosion Heard in Central Baghdad (Reut...  \n",
      "1  Israel OKs More West Bank Settlement Homes JER...  \n",
      "2  Scores of Iraqis die in 3 days of attacks US t...  \n",
      "3  At least 20 dead in Kurkik bombing A suicide a...  \n",
      "4  Israel, Egypt in Prisoner Swap  CAIRO (Reuters...  \n",
      "   label                                              title  \\\n",
      "0      0  Large Explosion Heard in Central Baghdad (Reut...   \n",
      "1      0         Israel OKs More West Bank Settlement Homes   \n",
      "2      0          Scores of Iraqis die in 3 days of attacks   \n",
      "3      0                 At least 20 dead in Kurkik bombing   \n",
      "4      0                     Israel, Egypt in Prisoner Swap   \n",
      "\n",
      "                                         description  \\\n",
      "0  Reuters - A large blast was heard in central\\B...   \n",
      "1  JERUSALEM Aug. 23, 2004 - Israel announced pla...   \n",
      "2  US troops fought a gunbattle with insurgents a...   \n",
      "3  A suicide attacker detonated a car bomb near a...   \n",
      "4   CAIRO (Reuters) - Israel released six Egyptia...   \n",
      "\n",
      "                                                text  \n",
      "0  Large Explosion Heard in Central Baghdad (Reut...  \n",
      "1  Israel OKs More West Bank Settlement Homes JER...  \n",
      "2  Scores of Iraqis die in 3 days of attacks US t...  \n",
      "3  At least 20 dead in Kurkik bombing A suicide a...  \n",
      "4  Israel, Egypt in Prisoner Swap  CAIRO (Reuters...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3800/3800 [00:00<00:00, 6264.27 examples/s]\n",
      "Map: 100%|██████████| 3800/3800 [00:00<00:00, 6789.81 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\jothi\\AppData\\Local\\Temp\\ipykernel_12328\\1562231422.py:131: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments created with supported params: ['output_dir', 'learning_rate', 'per_device_train_batch_size', 'per_device_eval_batch_size', 'num_train_epochs', 'weight_decay', 'logging_dir', 'logging_steps', 'eval_strategy', 'save_strategy', 'load_best_model_at_end']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/13 20:53:15 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "c:\\Users\\jothi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='714' max='714' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [714/714 2:01:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.366800</td>\n",
       "      <td>0.256807</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.920608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.234800</td>\n",
       "      <td>0.178232</td>\n",
       "      <td>0.949474</td>\n",
       "      <td>0.949290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.152208</td>\n",
       "      <td>0.960263</td>\n",
       "      <td>0.960192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jothi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\jothi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\jothi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15220767259597778, 'eval_accuracy': 0.9602631578947368, 'eval_f1': 0.9601919772092182, 'eval_runtime': 500.337, 'eval_samples_per_second': 7.595, 'eval_steps_per_second': 0.476, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./distilbert_agnews_model.h5\\\\tokenizer_config.json',\n",
       " './distilbert_agnews_model.h5\\\\special_tokens_map.json',\n",
       " './distilbert_agnews_model.h5\\\\vocab.txt',\n",
       " './distilbert_agnews_model.h5\\\\added_tokens.json',\n",
       " './distilbert_agnews_model.h5\\\\tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install transformers datasets scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------\n",
    "# 1. Load Dataset (AG News)\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your 50% subset\n",
    "train_df = pd.read_csv(r\"C:\\Users\\jothi\\Desktop\\AG NEWS PROJECT\\train_50_percent.csv\", header=0)\n",
    "test_df  = pd.read_csv(r\"C:\\Users\\jothi\\Desktop\\AG NEWS PROJECT\\test_50_percent.csv\", header=0)\n",
    "\n",
    "# Columns: [label, title, description]\n",
    "train_df.columns = [\"label\", \"title\", \"description\"]\n",
    "test_df.columns  = [\"label\", \"title\", \"description\"]\n",
    "\n",
    "# Convert labels to integers\n",
    "train_df[\"label\"] = train_df[\"label\"].astype(int) - 1\n",
    "test_df[\"label\"]  = test_df[\"label\"].astype(int) - 1\n",
    "\n",
    "# Combine title + description into one text column\n",
    "train_df[\"text\"] = train_df[\"title\"].astype(str) + \" \" + train_df[\"description\"].astype(str)\n",
    "test_df[\"text\"]  = test_df[\"title\"].astype(str) + \" \" + test_df[\"description\"].astype(str)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"text\", \"label\"]])\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"text\", \"label\"]])\n",
    "\n",
    "# --------------------------\n",
    "# 2. Tokenization\n",
    "# --------------------------\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Remove text column & format for torch\n",
    "train_dataset = train_dataset.remove_columns([\"text\"])\n",
    "test_dataset = test_dataset.remove_columns([\"text\"])\n",
    "train_dataset.set_format(\"torch\")\n",
    "test_dataset.set_format(\"torch\")\n",
    "\n",
    "# --------------------------\n",
    "# 3. Load Pretrained Model\n",
    "# --------------------------\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=4\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 4. Define Metrics (scikit-learn)\n",
    "# --------------------------\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "# --------------------------\n",
    "# 5. Training Arguments\n",
    "# --------------------------\n",
    "import inspect\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Basic common kwargs (edit these hyperparams as needed)\n",
    "common_kwargs = {\n",
    "    \"output_dir\": \"./results\",\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"per_device_eval_batch_size\": 16,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"logging_dir\": \"./logs\",\n",
    "    \"logging_steps\": 100,\n",
    "}\n",
    "\n",
    "# Inspect the TrainingArguments __init__ signature to see supported parameter names\n",
    "sig = inspect.signature(TrainingArguments.__init__)\n",
    "param_names = set(sig.parameters.keys())\n",
    "param_names.discard(\"self\")  # not a real kwarg\n",
    "\n",
    "# Add evaluation/save related kwargs using the names available in this version\n",
    "if \"eval_strategy\" in param_names:\n",
    "    common_kwargs[\"eval_strategy\"] = \"epoch\"      # new name in recent versions\n",
    "elif \"evaluation_strategy\" in param_names:\n",
    "    common_kwargs[\"evaluation_strategy\"] = \"epoch\"  # older name\n",
    "\n",
    "if \"save_strategy\" in param_names:\n",
    "    common_kwargs[\"save_strategy\"] = \"epoch\"\n",
    "elif \"save_steps\" in param_names:\n",
    "    common_kwargs[\"save_steps\"] = 500\n",
    "\n",
    "# load_best_model_at_end exists in many versions; add only if supported\n",
    "if \"load_best_model_at_end\" in param_names:\n",
    "    common_kwargs[\"load_best_model_at_end\"] = True\n",
    "\n",
    "# Finally construct TrainingArguments\n",
    "try:\n",
    "    training_args = TrainingArguments(**common_kwargs)\n",
    "    print(\"TrainingArguments created with supported params:\", list(common_kwargs.keys()))\n",
    "except TypeError as e:\n",
    "    # Fallback: create a minimal TrainingArguments without eval/save-related options\n",
    "    print(\"Fallback: some kwargs not supported. Error:\", e)\n",
    "    minimal_kwargs = {\n",
    "        \"output_dir\": \"./results\",\n",
    "        \"per_device_train_batch_size\": 16,\n",
    "        \"per_device_eval_batch_size\": 16,\n",
    "        \"num_train_epochs\": 3,\n",
    "    }\n",
    "    training_args = TrainingArguments(**minimal_kwargs)\n",
    "    print(\"Fallback TrainingArguments created (minimal).\")\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 6. Trainer API\n",
    "# --------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 7. Train the Model\n",
    "# --------------------------\n",
    "trainer.train()\n",
    "\n",
    "# --------------------------\n",
    "# 8. Evaluate\n",
    "# --------------------------\n",
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "\n",
    "# --------------------------\n",
    "# 9. Save Model\n",
    "# --------------------------\n",
    "trainer.save_model(\"./distilbert_agnews_model.h5\")\n",
    "tokenizer.save_pretrained(\"./distilbert_agnews_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6495bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b23e4d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jothi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.98      0.93      0.96       950\n",
      "      Sports       0.98      0.99      0.99       950\n",
      "    Business       0.95      0.93      0.94       950\n",
      "    Sci/Tech       0.94      0.98      0.96       950\n",
      "\n",
      "    accuracy                           0.96      3800\n",
      "   macro avg       0.96      0.96      0.96      3800\n",
      "weighted avg       0.96      0.96      0.96      3800\n",
      "\n",
      "\n",
      "📊 Confusion Matrix:\n",
      "[[887  14  33  16]\n",
      " [  4 942   4   0]\n",
      " [ 13   1 888  48]\n",
      " [  3   1  14 932]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------\n",
    "# 10. Predictions on Test Set\n",
    "# --------------------------\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_true = predictions.label_ids\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# --------------------------\n",
    "# 11. Classification Report\n",
    "# --------------------------\n",
    "print(\"\\n📊 Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]))\n",
    "\n",
    "# --------------------------\n",
    "# 12. Confusion Matrix\n",
    "# --------------------------\n",
    "print(\"\\n📊 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe0fb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(4, 3))  # Small size\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14c8c2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['distilbert_model.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_bert, \"distilbert_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40dcdf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_bert.save(\"distilbert_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a47cd882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tabulate.exe is installed in 'c:\\Users\\jothi\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5cd7cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Article Classifier Comparison:\n",
      "\n",
      "+---------------------+--------------+------------+------------+----------------------------------------------+---------------------------------------------+\n",
      "| Model Name          | Model Type   |   Accuracy |   F1-Score | Pros                                         | Cons                                        |\n",
      "+=====================+==============+============+============+==============================================+=============================================+\n",
      "| Logistic Regression | ML           |       0.92 |       0.92 | 1. Fast training and inference               | 1. Limited to linear decision boundaries    |\n",
      "|                     |              |            |            | 2. Easy to interpret and implement           | 2. Poor performance on long or complex text |\n",
      "|                     |              |            |            | 3. Good for linearly separable text          | 3. Requires manual feature engineering      |\n",
      "+---------------------+--------------+------------+------------+----------------------------------------------+---------------------------------------------+\n",
      "| GRU                 | DL           |       0.91 |       0.91 | 1. Captures sequential dependencies          | 1. Slower training than ML models           |\n",
      "|                     |              |            |            | 2. Handles variable-length input             | 2. Sensitive to vanishing gradients         |\n",
      "|                     |              |            |            | 3. Suitable for moderately complex NLP tasks | 3. Needs careful hyperparameter tuning      |\n",
      "+---------------------+--------------+------------+------------+----------------------------------------------+---------------------------------------------+\n",
      "| DistilBERT          | Pre-trained  |       0.96 |       0.96 | 1. Excellent contextual understanding        | 1. High memory and compute requirements     |\n",
      "|                     |              |            |            | 2. Pre-trained on large corpora              | 2. Slower inference speed                   |\n",
      "|                     |              |            |            | 3. High accuracy with fine-tuning            | 3. May overfit on small datasets            |\n",
      "+---------------------+--------------+------------+------------+----------------------------------------------+---------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Define the data\n",
    "headers = [\"Model Name\", \"Model Type\", \"Accuracy\", \"F1-Score\", \"Pros\", \"Cons\"]\n",
    "rows = [\n",
    "    [\n",
    "        \"Logistic Regression\", \"ML\", 0.92, 0.92,\n",
    "        \"1. Fast training and inference\\n2. Easy to interpret and implement\\n3. Good for linearly separable text\",\n",
    "        \"1. Limited to linear decision boundaries\\n2. Poor performance on long or complex text\\n3. Requires manual feature engineering\"\n",
    "    ],\n",
    "    [\n",
    "        \"GRU\", \"DL\", 0.91, 0.91,\n",
    "        \"1. Captures sequential dependencies\\n2. Handles variable-length input\\n3. Suitable for moderately complex NLP tasks\",\n",
    "        \"1. Slower training than ML models\\n2. Sensitive to vanishing gradients\\n3. Needs careful hyperparameter tuning\"\n",
    "    ],\n",
    "    [\n",
    "        \"DistilBERT\", \"Pre-trained\", 0.96, 0.96,\n",
    "        \"1. Excellent contextual understanding\\n2. Pre-trained on large corpora\\n3. High accuracy with fine-tuning\",\n",
    "        \"1. High memory and compute requirements\\n2. Slower inference speed\\n3. May overfit on small datasets\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Print the table\n",
    "print(\"News Article Classifier Comparison:\\n\")\n",
    "print(tabulate(rows, headers=headers, tablefmt=\"grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
